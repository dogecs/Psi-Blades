{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudah', 'dilakukan', 'sesuai', 'pesan', 'belum', 'bisa']\n",
      "\n",
      "type :  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# convert list formated string to list\n",
    "import ast\n",
    "import numpy as np\n",
    "index = 0\n",
    "\n",
    "def convert_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return [text for text in texts]\n",
    "\n",
    "data['Data Teks_List'] = data['Data Teks_Token'].apply(convert_text_list)\n",
    "\n",
    "\n",
    "print(data['Data Teks_List'][index])\n",
    "\n",
    "print('\\ntype : ', type(data['Data Teks_List']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'sudah': 0.16666666666666666, 'dilakukan': 0....\n",
       "1                                           {'p': 1.0}\n",
       "2    {'kak': 0.041666666666666664, 'dila': 0.041666...\n",
       "3    {'ini': 0.14285714285714285, 'kapan': 0.071428...\n",
       "4    {'oy': 0.08333333333333333, 'mola': 0.08333333...\n",
       "Name: TF_dict, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_TF(document):\n",
    "    # Counts the number of times the word appears in review\n",
    "    TF_dict = {}\n",
    "    for term in document:\n",
    "        if term in TF_dict:\n",
    "            TF_dict[term] += 1\n",
    "        else:\n",
    "            TF_dict[term] = 1\n",
    "    # Computes tf for each word\n",
    "    for term in TF_dict:\n",
    "        TF_dict[term] = TF_dict[term] / len(document)\n",
    "    return TF_dict\n",
    "\n",
    "data[\"TF_dict\"] = data['Data Teks_List'].apply(calc_TF)\n",
    "\n",
    "data[\"TF_dict\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t TF\n",
      "\n",
      "               sudah \t 0.16666666666666666\n",
      "           dilakukan \t 0.16666666666666666\n",
      "              sesuai \t 0.16666666666666666\n",
      "               pesan \t 0.16666666666666666\n",
      "               belum \t 0.16666666666666666\n",
      "                bisa \t 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('%20s' % \"term\", \"\\t\", \"TF\\n\")\n",
    "for key in data[\"TF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", data[\"TF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_DF(tfDict):\n",
    "    count_DF = {}\n",
    "    # Run through each document's tf dictionary and increment countDict's (term, doc) pair\n",
    "    for document in tfDict:\n",
    "        for term in document:\n",
    "            if term in count_DF:\n",
    "                count_DF[term] += 1\n",
    "            else:\n",
    "                count_DF[term] = 1\n",
    "    return count_DF\n",
    "\n",
    "DF = calc_DF(data[\"TF_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_document = len(data)\n",
    "\n",
    "def calc_IDF(__n_document, __DF):\n",
    "    IDF_Dict = {}\n",
    "    for term in __DF:\n",
    "        IDF_Dict[term] = np.log(__n_document / (__DF[term] + 1))\n",
    "    return IDF_Dict\n",
    "  \n",
    "#Stores the idf dictionary\n",
    "IDF = calc_IDF(n_document, DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc TF-IDF\n",
    "def calc_TF_IDF(TF):\n",
    "    TF_IDF_Dict = {}\n",
    "    #For each word in the review, we multiply its tf and its idf.\n",
    "    for key in TF:\n",
    "        TF_IDF_Dict[key] = TF[key] * IDF[key]\n",
    "    return TF_IDF_Dict\n",
    "\n",
    "#Stores the TF-IDF Series\n",
    "data[\"TF-IDF_dict\"] = data[\"TF_dict\"].apply(calc_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t         TF \t              TF-IDF\n",
      "\n",
      "               sudah \t 0.16666666666666666 \t 0.2542200919300053\n",
      "           dilakukan \t 0.16666666666666666 \t 0.6251534177936807\n",
      "              sesuai \t 0.16666666666666666 \t 0.8623381401674486\n",
      "               pesan \t 0.16666666666666666 \t 0.2018062581670243\n",
      "               belum \t 0.16666666666666666 \t 0.5516581183661684\n",
      "                bisa \t 0.16666666666666666 \t 0.31884197335297587\n"
     ]
    }
   ],
   "source": [
    "print('%20s' % \"term\", \"\\t\", '%10s' % \"TF\", \"\\t\", '%20s' % \"TF-IDF\\n\")\n",
    "for key in data[\"TF-IDF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", data[\"TF_dict\"][index][key] ,\"\\t\" , data[\"TF-IDF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "[0.0, 0.0, 0.2018062581670243, 0.0, 0.0, 0.0, 0.2542200919300053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31884197335297587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "matrix size :  50\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(DF.items(), key=lambda kv: kv[1], reverse=True)[:50]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "data[\"TF_IDF_Vec\"] = data[\"TF-IDF_dict\"].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(data[\"TF_IDF_Vec\"][0])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(data[\"TF_IDF_Vec\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('E:\\Program\\[2] Program\\AnSent\\Data\\Data_8_Pemod\\Mod_Indihome.csv')\n",
    "# data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
